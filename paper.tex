\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{hyperref}

\usepackage{amsthm}

\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}

\author{Marten Lienen}
\date{\today}
\title{Computations with random variables}

\begin{document}

\maketitle

\section{Introduction}

\section{Our Approach}

\subsection{Basic Arithmethic}

Let $X, Y$ be two independent random variables with gaussian mixture
distributions.
\begin{equation*}
  X \sim \sum_{i = 1}^{n} \alpha_{i} \cdot \mathcal{N}(\mu_{i}, \sigma_{i}^{2}) \qquad Y \sim \sum_{i = 1}^{m} \beta_{i} \cdot \mathcal{N}(\nu_{i}, \tau_{i}^{2})
\end{equation*}
For future reference we will also define random variables for the components.
\begin{equation*}
  X_{i} \sim \mathcal{N}(\mu_{i}, \sigma_{i}^{2}) \qquad Y_{i} \sim \mathcal{N}(\nu_{i}, \tau_{i}^{2})
\end{equation*}

Let $f : \mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}$ be monotonic and
invertible in the first argument and $Z = f(X, Y)$ the application of $f$ to $X$
and $Y$.

\begin{lemma}
  The joint PDF of $Z$ and $Y$ is expressible in terms of the joint PDF of $X$
  and $Y$.
\end{lemma}
\begin{proof}
  Let $x = f^{-1}(y, z)$.
  \begin{align*}
    p(Z = z, Y = y) & = p(Z = z \mid Y = y) \cdot p(Y = y)\\
                    & = \left| \frac{\mathrm{d}x}{\mathrm{d}z} \right| \cdot p(X = f^{-1}(y, z) \mid Y = y) \cdot p(Y = y) \quad\textit{Change of Variables, Murphy 2.6.2}\\
                    & = \left| \frac{\mathrm{d}x}{\mathrm{d}z} \right| \cdot p(X = f^{-1}(y, z)) \cdot p(Y = y) \quad\textit{$X$ and $Y$ are independent}\\
                    & = \left| \frac{\mathrm{d}x}{\mathrm{d}z} \right| \cdot p(X = f^{-1}(y, z), Y = y)
  \end{align*}
\end{proof}

Using this result we can infer the general form of $Z$.

\begin{lemma}
  $Z$ has a mixture distribution with $n \cdot m$ components.
  \begin{equation*}
    p(Z = z) = \sum_{i = 1}^{n} \sum_{j = 1}^{m} \alpha_{i}\beta_{j} \cdot p(f(X_{i}, Y_{j}) = z)
  \end{equation*}
\end{lemma}
\begin{proof}
  \begin{align*}
    p(Z = z) & = \int_{-\infty}^{\infty} p(Z = z, Y = y)~\mathrm{d}y\\
             & = \int_{-\infty}^{\infty} \left| \frac{\mathrm{d}x}{\mathrm{d}z} \right| \cdot p(X = f^{-1}(y, z)) \cdot p(Y = y)~\mathrm{d}y\\
             & = \int_{-\infty}^{\infty} \left| \frac{\mathrm{d}x}{\mathrm{d}z} \right| \cdot \left( \sum_{i = 1}^{n} \alpha_{i} \cdot \mathcal{N}(f^{-1}(y, z) \mid \mu_{i}, \sigma_{i}^{2}) \right) \cdot \left( \sum_{j = 1}^{m} \beta_{j} \cdot \mathcal{N}(y \mid \nu_{j}, \tau_{j}^{2}) \right)~\mathrm{d}y\\
             & = \sum_{i = 1}^{n} \sum_{j = 1}^{m} \alpha_{i}\beta_{j} \int_{-\infty}^{\infty} \left| \frac{\mathrm{d}x}{\mathrm{d}z} \right| \cdot \mathcal{N}(f^{-1}(y, z) \mid \mu_{i}, \sigma_{i}^{2}) \cdot \mathcal{N}(y \mid \nu_{j}, \tau_{j}^{2})~\mathrm{d}y\\
             & = \sum_{i = 1}^{n} \sum_{j = 1}^{m} \alpha_{i}\beta_{j} \int_{-\infty}^{\infty} \left| \frac{\mathrm{d}x}{\mathrm{d}z} \right| \cdot p(X_{i} = f^{-1}(y, z)) \cdot p(Y_{j} = y)~\mathrm{d}y\\
             & = \sum_{i = 1}^{n} \sum_{j = 1}^{m} \alpha_{i}\beta_{j} \int_{-\infty}^{\infty} p(f(X_{i}, y) = z, Y_{j} = y)~\mathrm{d}y\\
             & = \sum_{i = 1}^{n} \sum_{j = 1}^{m} \alpha_{i}\beta_{j} \cdot p(f(X_{i}, Y_{j}) = z)
  \end{align*}
\end{proof}

However with a general $f$ we cannot determine the component distributions. But
in specific cases this might be possible, as we see in the next example.

\begin{example}
  If $f = +$ or $f = -$, $f$ is monotonic and invertible in the first
  argument. Also $f$ of two normally distributed random variables is again
  normally distributed, so $Z$ is another mixture of gaussians with components
  \begin{equation*}
    Z_{i,j} \sim \mathcal{N}(\mu_{i} + \nu_{j}, \sigma_{i}^{2} + \tau_{j}^{2})
  \end{equation*}
\end{example}

\begin{lemma}
  If $f(X_{i}, Y_{j})$ has a gaussian mixture distribution with $o_{i,j}$
  components, $Z$ has a gaussian mixture distribution with
  $\sum_{i = 1}^{n} \sum_{j = 1}^{m} o_{i,j}$ components.
\end{lemma}

\begin{proof}
  Trivial.
\end{proof}

\end{document}